{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce834d4-2100-4f91-983c-8edc95e64809",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/use_cases/chatbots/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556bcfe-c51e-4a73-b45c-e03ea9f5c034",
   "metadata": {},
   "source": [
    "The chatbot interface is based around messages rather than raw text, and is best suited to Chat Models rather than text completion LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14281182-6db8-49f0-8a49-739b2177f7e1",
   "metadata": {},
   "source": [
    "Generally the difference between Models and ChatModels, PromptTemplates and ChatPromptTemplates, Prompts and Messages, is that the formers are designed for string input->outputs, whereas the latters are designed for lists of conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3c861-1ffd-46a4-9599-ebf0f3fcc7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain langchain-openai typing-inspect typing_extensions pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a77895-698c-48a4-845a-7bd56150fd24",
   "metadata": {},
   "source": [
    "## A Basic ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be35808a-b4cc-4311-a6de-e05d5dfe2412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1971c1c-7490-468c-a7b7-8a5869cd2e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Translate this sentence from English to French: I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c7d2f-3825-4f86-a972-e6827b5f5a65",
   "metadata": {},
   "source": [
    "This input prompt can be wrapped more properly to differentiated better from AI messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4463cc-3d6a-442c-af1a-53e1b21bcffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "chat_model.invoke([HumanMessage(\"Translate this sentence from English to French: I love programming.\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3df088-5d49-485b-adc7-e34c92d4c56e",
   "metadata": {},
   "source": [
    "The model on its own does not have any history or state, so if you ask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d13e108-17a1-4b43-bdea-ad5d3d78aeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"What did you just say?\"')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke([HumanMessage(content=\"What did you just say?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8aff1-e7d0-402a-a46d-7ff165660531",
   "metadata": {},
   "source": [
    "It doesn’t take the previous conversation turn into context, and cannot answer the question.\n",
    "\n",
    "To get around this, **we need to pass the entire conversation history** into the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc86930-1b8f-4e83-b465-d80de7a2b97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8f3d35-44c5-49de-9aff-e574dac7a574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"J\\'adore la programmation\" which means \"I love programming\" in French.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\n",
    "    [\n",
    "        HumanMessage(\"Translate this sentence from English to French: I love programming.\"),\n",
    "        AIMessage(content=\"J'adore la programmation.\"),\n",
    "        HumanMessage(\"What did you just say?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d03a7c-464f-4081-b13b-a88f44a2de48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"J\\'adore la programmation,\" which means \"I love programming\" in French.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\n",
    "    [\n",
    "        HumanMessage(\"Translate this sentence from English to French: I love programming.\"),\n",
    "        AIMessage(\"J'adore la programmation.\"),\n",
    "        HumanMessage(\"What did you just say?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059eedd-2d2c-4cf1-a259-747786b1356c",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc8daf5-cd5b-42e3-9f27-f6272a008fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38dc657-54b8-4f6f-a7f8-87198749f911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a789c-ae72-41d5-9b77-213f5d87e61e",
   "metadata": {},
   "source": [
    "In the above definition of `prompt`, `MessagesPlaceholder(variable_name=\"messages\")` is going to be responsible for taking in the entire set of input messages all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6da4be0-c816-4d55-9648-3a91442da7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"J\\'adore la programmation,\" which means \"I love programming\" in French.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate this sentence from English to French: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb7646-6198-4054-9aeb-f6ffda9ec22e",
   "metadata": {},
   "source": [
    "### Message History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0cf6c-f2a3-4ff2-9e97-cdb94c02033b",
   "metadata": {},
   "source": [
    "We can use an **in-memory**, demo message history called `ChatMessageHistory` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb11047-8afb-40cb-8097-efbbf0e2123c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5624f4b-40f4-4c53-ac81-7b84aa43340a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"hi!\")\n",
    "\n",
    "chat_history.add_ai_message(\"whats up?\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1993433-10bd-44e2-aa3c-44bf87c4bc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"I love programming\" in French is \"J\\'adore la programmation.\"')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84196f98-c2da-498d-956a-c5ccfdd4b29b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"J\\'adore la programmation,\" which means \"I love programming\" in French.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_ai_message(response)\n",
    "\n",
    "chat_history.add_user_message(\"What did you just say?\")\n",
    "\n",
    "chain.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf6b2008-4b68-4a88-81ec-7fed8f8b2a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'),\n",
       " AIMessage(content='whats up?'),\n",
       " HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       " HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       " AIMessage(content='The translation of \"I love programming\" in French is \"J\\'adore la programmation.\"'),\n",
       " HumanMessage(content='What did you just say?')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4abe29-d462-4e3b-8cc5-7373bd989920",
   "metadata": {},
   "source": [
    "This is a basic chatbot!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffe0ac-b6ca-40a4-8466-6ebe503cd071",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bc5fc-b0a4-42fc-8cbb-7ebbf0d3ab85",
   "metadata": {},
   "source": [
    "In order to pull domain-specific knowledge for our chatbot, we can use `retrievers`.\n",
    "\n",
    "The dependencies needed for retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ac2dfc-b2be-4507-9b4f-4fb3e29a0fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet chromadb beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395970a1-6178-4d92-b402-8917a009017d",
   "metadata": {},
   "source": [
    "### Web-doc retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f037082-d8c4-48a6-aabb-1bd4b86d6d12",
   "metadata": {},
   "source": [
    "We use the `LangSmith documentation` as source and store it in a `Chromadb` vectorstore for retrieval.\n",
    "\n",
    "A WebBaseLoader from document_loaders can be used for loading web pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b9e87b-ceae-4c61-870a-98c0b032ae0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f94a825-d4bc-41a8-ad60-df88d2b9dc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Defining a text_splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# Applying the text_splitter to our web data\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9d3b9-dcb9-4382-8adb-85ad61320435",
   "metadata": {},
   "source": [
    "Then we embed and store those chunks in a vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a040dbe-376f-49fb-b2a4-bcc86429f398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# This line grabs the document chunks, takes them to the embedding space, and stores them in the db.\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d3482-00d1-446c-a959-d17686e3add5",
   "metadata": {},
   "source": [
    "Now, we can test our retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b09bfc-69c9-4c3e-8520-b2d5bf91f4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangSmith | 🦜️🛠️ LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith | 🦜️🛠️ LangSmith'}),\n",
       " Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith | 🦜️🛠️ LangSmith'}),\n",
       " Document(page_content='for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith | 🦜️🛠️ LangSmith'}),\n",
       " Document(page_content='environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith | 🦜️🛠️ LangSmith'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k is the number of items to retrieve\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "docs = retriever.invoke(\"Is Langsmith free?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aff38b-5e69-414b-bbe4-c2ddabd1cae7",
   "metadata": {},
   "source": [
    "### Represent Documents as Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266ee37-f16e-48d9-aa6f-62301a1b8429",
   "metadata": {},
   "source": [
    "The `create_stuff_documents_chain` helper function packs all of the input documents into the prompt, as the context.\n",
    "\n",
    "Other arguments (like messages) will be passed directly through into the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c21edea-d9d7-4f0e-92c6-d5f314cd80de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat_model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6baf05ac-b979-4141-8294-171b9a7aa7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith can help with testing by providing capabilities to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. It seamlessly integrates with LangChain, the open source framework for building with LLMs. Through LangSmith, users can access tracing and evaluation quick starts to begin testing their applications, and they can also learn about the workflows and capabilities supported at each stage of the LLM application lifecycle through the User Guide. Additionally, LangSmith offers a Prompt Hub, a prompt management tool built into the platform, to further aid in testing and development.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"how can langsmith help with testing?\")\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"messages\": chat_history.messages,\n",
    "        \"context\": docs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4430868-422a-4c67-8445-682e529ed9d1",
   "metadata": {},
   "source": [
    "We have an answer, generated from the relevant retrieved information of the Langsmith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ac9db-e9c2-4646-9ce7-393476ef10f9",
   "metadata": {},
   "source": [
    "### Creating a retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2651e-430d-4735-a479-d1235bf9d864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
